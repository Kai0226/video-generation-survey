
### Multi-modality Generation 

[arxiv 2023.07]Generative Pretraining in Multimodality [[PDF](https://arxiv.org/abs/2307.05222),[Page](https://github.com/baaivision/Emu)]

[arxiv 2023.07]Generating Images with Multimodal Language Models [[PDF](https://arxiv.org/abs/2305.17216),[Page](https://jykoh.com/gill)]

[arxiv 2023.07]3D-LLM: Injecting the 3D World into Large Language Models[[PDF] (https://arxiv.org/abs/2307.12981),[Page](https://vis-www.cs.umass.edu/3dllm/)]

[arxiv 2023.10]Making LLaMA SEE and Draw with SEED Tokenizer [[PDF](https://arxiv.org/abs/2310.01218),[Page](https://github.com/AILab-CVC/SEED)]

[arxiv 2023.10]Iterative Self-Refinement with GPT-4V(ision) for Automatic Image Design and Generation [[PDf](https://arxiv.org/abs/2310.08541),[Page](https://idea2img.github.io/)]

[arxiv 2023.12]CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation[[PDF](https://arxiv.org/abs/2311.18775),[Page](https://codi-2.github.io/)]

[arxiv 2023.12]SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models [[PDF](https://arxiv.org/abs/2312.06739),[Page](https://yuzhou914.github.io/SmartEdit/)]
