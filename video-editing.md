# Video Editing

[ECCV 2022] Text2LIVE: Text-Driven Layered Image and Video Editing [[PDF](https://arxiv.org/abs/2204.02491)]

[SIGGRAPH ASIA 2021] Layered Neural Atlases for Consistent Video Editing [[Page](https://github.com/ykasten/layered-neural-atlases)]

[ECCVW 2022] Text-Driven Stylization of Video Objects [[PDF](https://arxiv.org/pdf/2206.12396.pdf)]

[arxiv 2023.01]Shape-aware Text-driven Layered Video Editing [[PDF](https://arxiv.org/abs/2301.13173), [Page](https://text-video-edit.github.io/)]

## Diffusion-based 
[arxiv 2022.12]Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding \[[PDF](https://arxiv.org/pdf/2212.02802.pdf)\]

[arxiv 2023.01]Dreamix: Video Diffusion Models are General Video Editors [[PDF](https://arxiv.org/abs/2302.01329),[Page](https://dreamix-video-editing.github.io/)]


## Image Model for video editing 
[arxiv 2022.12]Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation [[PDF](https://arxiv.org/abs/2212.11565), [Page](https://tuneavideo.github.io/)]

[arxiv 2023.03]Video-P2P: Video Editing with Cross-attention Control [[PDF](https://arxiv.org/abs/2303.04761), [Page](https://video-p2p.github.io/)]

[arxiv 2023.03]Edit-A-Video: Single Video Editing with Object-Aware Consistency [[PDF](https://arxiv.org/abs/2303.07945), [Page](https://edit-a-video.github.io/)]

[arxiv 2023.03]FateZero: Fusing Attentions for Zero-shot Text-based Video Editing [[PDF](https://arxiv.org/abs/2303.09535), [Page](https://github.com/ChenyangQiQi/FateZero)]

[arxiv 2023.03]Pix2Video: Video Editing using Image Diffusion [[PDF](https://arxiv.org/abs/2303.12688)]

[arxiv 2023.03]Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators [[PDF](https://arxiv.org/abs/2303.13439), [code](https://github.com/Picsart-AI-Research/Text2Video-Zero)]

[arxiv 2023.03]Conditional Image-to-Video Generation with Latent Flow Diffusion Models [[PDF](https://arxiv.org/abs/2303.13744)]


## Related 
[CVPR 2023]3D Cinemagraphy from a Single Image[[PDF](https://arxiv.org/abs/2303.05724), [Page](https://xingyi-li.github.io/3d-cinemagraphy/)]
