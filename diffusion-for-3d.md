# Diffusion for 3D Generation

[arxiv 2022; Nvidia] Magic3D: High-Resolution Text-to-3D Content Creation \[[PDF](https://deepimagination.cc/Magic3D/), code\]

[arxiv 2022; google] DreamFusion: Text-to-3D using 2D Diffusion [[PDF](https://dreamfusion3d.github.io/), [code(unofficial)](https://github.com/ashawkey/stable-dreamfusion)]

[arxiv 2022.11; ]DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model \[[PDF](https://arxiv.org/pdf/2211.12824.pdf), code\]

[arxiv 2022.1; ]Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models [[PDF](https://arxiv.org/abs/2212.14704), [Page](https://bluestyle97.github.io/dream3d/)]

[arixv 2023.02] TEXTure: Text-Guided Texturing of 3D Shapes[[PDF](https://arxiv.org/abs/2302.01721), [Page](https://texturepaper.github.io/TEXTurePaper/)]

